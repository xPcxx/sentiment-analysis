{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d230d74-d3c3-4d12-a2b7-3d0dd98922fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Load your Naive Bayes model and TfidfVectorizer\n",
    "nb_model_loaded = load('naive_bayes_model.joblib')\n",
    "tfidf_vectorizer_loaded = load('tfidf_vectorizer.joblib')\n",
    "\n",
    "# Preprocessing functions (from previous implementation)\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data (if not already downloaded)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Lancaster stemmer and lemmatizer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define preprocessing functions\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def apply_stemming(words):\n",
    "    return [lancaster_stemmer.stem(word) for word in words]\n",
    "\n",
    "def apply_lemmatization(words):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "# Full text preprocessing pipeline\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = remove_html_tags(text)\n",
    "    text = remove_punc(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_emoji(text)\n",
    "    \n",
    "    # Tokenization\n",
    "    sentences = sent_tokenize(text)\n",
    "    tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "    \n",
    "    # Stemming and Lemmatization\n",
    "    stemmed_sentences = [apply_stemming(sentence) for sentence in tokenized_sentences]\n",
    "    lemmatized_sentences = [apply_lemmatization(sentence) for sentence in stemmed_sentences]\n",
    "    \n",
    "    return ' '.join([word for sublist in lemmatized_sentences for word in sublist])\n",
    "\n",
    "# Streamlit application starts here\n",
    "def main():\n",
    "    # Title of your web app\n",
    "    st.title(\"Amazon Product Review Sentiment Analysis App\")\n",
    "\n",
    "    # Sidebar for navigation\n",
    "    st.sidebar.title(\"Options\")\n",
    "    option = st.sidebar.selectbox(\"Choose how to input data\", [\"Enter text\", \"Upload file\"])\n",
    "\n",
    "    if option == \"Enter text\":\n",
    "        # Text box for user input\n",
    "        user_input = st.text_input(\"Enter a product review to check sentiment:\")\n",
    "\n",
    "        # Predict button\n",
    "        if st.button('Predict'):\n",
    "            if user_input:  # Check if the input is not empty\n",
    "                predict_and_display([user_input])  # Single sentence prediction\n",
    "            else:\n",
    "                st.error(\"Please enter a review for prediction.\")\n",
    "    else:  # Option to upload file\n",
    "        uploaded_file = st.file_uploader(\"Choose a file\", type=['txt', 'csv'])\n",
    "        if uploaded_file is not None:\n",
    "            if uploaded_file.type == \"text/csv\" or uploaded_file.name.endswith('.csv'):\n",
    "                data = pd.read_csv(uploaded_file)\n",
    "            else:  # Assume text file\n",
    "                data = pd.read_table(uploaded_file, header=None, names=['text'])\n",
    "\n",
    "            # Check if the file has content\n",
    "            if not data.empty:\n",
    "                reviews = data['text'].tolist()\n",
    "                predict_and_display(reviews)  # File-based prediction\n",
    "\n",
    "def predict_and_display(reviews):\n",
    "    # Preprocess the reviews\n",
    "    preprocessed_reviews = [preprocess_text(review) for review in reviews]\n",
    "\n",
    "    # Transform the preprocessed reviews\n",
    "    transformed_reviews = tfidf_vectorizer_loaded.transform(preprocessed_reviews)\n",
    "\n",
    "    # Make predictions\n",
    "    results = nb_model_loaded.predict(transformed_reviews)\n",
    "\n",
    "    # Combine the inputs and predictions into a DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Input': reviews,\n",
    "        'Prediction': [\"Positive\" if label == 1 else \"Negative\" for label in results]\n",
    "    })\n",
    "\n",
    "    # Tabulate and display the results\n",
    "    with st.expander(\"Show/Hide Prediction Table\"):\n",
    "        st.table(results_df)\n",
    "\n",
    "    # Display histogram of predictions\n",
    "    st.write(\"Histogram of Predictions:\")\n",
    "    fig, ax = plt.subplots()\n",
    "    prediction_counts = pd.Series(results).value_counts().sort_index()\n",
    "    prediction_counts.index = [\"Negative\", \"Positive\"]\n",
    "    prediction_counts.plot(kind='bar', ax=ax)\n",
    "    ax.set_title(\"Number of Positive and Negative Predictions\")\n",
    "    ax.set_xlabel(\"Category\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.yaxis.set_major_locator(ticker.MaxNLocator(integer=True))  # Ensure y-axis has integer ticks\n",
    "    st.pyplot(fig)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
